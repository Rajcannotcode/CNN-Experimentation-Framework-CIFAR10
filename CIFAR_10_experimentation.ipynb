{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN59l2kfUu23KkqZux6WhLL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajcannotcode/CNN-Experimentation-Framework-CIFAR10/blob/main/CIFAR_10_experimentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10 Image Classification with CNNs\n",
        "\n",
        "This project presents a modular experimentation framework for training and evaluating convolutional neural networks (CNNs) on the CIFAR-10 dataset using PyTorch.\n",
        "\n",
        "Key components include:\n",
        "- Data augmentation pipelines to reduce overfitting and improve generalization\n",
        "- A centralized configuration block for easily adjusting hyperparameters\n",
        "- A structured experiment runner that logs results to a pandas DataFrame for easy analysis\n",
        "\n",
        "The notebook is designed for extensibility and reproducibility, enabling users to test and compare multiple training setups with minimal code changes.\n"
      ],
      "metadata": {
        "id": "aXmBqErYqRF6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjWCQlCKpe2d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import shutil"
      ],
      "metadata": {
        "id": "h96uPfvBJtZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from collections import namedtuple\n",
        "from itertools import product\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "CK5SGsAgSpog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU name: \",torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print('No GPU available')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wxvqqR5z8AWu",
        "outputId": "8f11f3cf-75ca-4d9d-a598-5c7122721dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data/CIFAR10',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform= transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "\n",
        "raw_testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data/CIFAR10',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform= transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2iAQ2oh8jgP",
        "outputId": "66bfbf9c-38ff-4943-c1c8-cfda019b4730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:10<00:00, 15.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer_loader = torch.utils.data.DataLoader(raw_trainset,batch_size = len(raw_trainset), shuffle=False)\n",
        "raw_train_data = next(iter(normalizer_loader))\n",
        "train_std = raw_train_data[0].std()\n",
        "train_mean = raw_train_data[0].mean()"
      ],
      "metadata": {
        "id": "ShrE7UhUCYRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation and Normalization\n",
        "\n",
        "In this section, we define transformations to prepare the CIFAR-10 dataset for training and evaluation.\n",
        "\n",
        "- **Normalization** is performed using the dataset’s global mean and standard deviation to ensure all features have a consistent scale, improving convergence during training.\n",
        "- **Data Augmentation** is applied to artificially increase the dataset diversity and reduce overfitting. We use:\n",
        "  - `RandomHorizontalFlip` to simulate mirrored objects\n",
        "  - `RandomCrop` with padding to introduce spatial jitter\n",
        "  - `RandomRotation` and `RandomVerticalFlip` (in the heavily augmented variant) to expose the model to rotated and flipped perspectives\n",
        "\n",
        "Two levels of augmentation are created:\n",
        "- `augmented_trainset_transformations` for general-purpose training\n",
        "- `heavily_augmented_trainset_transformations` for experimentation with stronger regularization\n"
      ],
      "metadata": {
        "id": "PjNSEOsnQ9fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_trainset= torchvision.datasets.CIFAR10(\n",
        "    root='./data/CIFAR10',\n",
        "    train =True,\n",
        "    download =True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=train_mean, std=train_std)\n",
        "    ])\n",
        ")\n",
        "\n",
        "normalized_testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data/CIFAR10',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform= transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=train_mean, std= train_std)\n",
        "    ])\n",
        ")\n",
        "\n",
        "normalized_trainset.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOLJa6SsCsd9",
        "outputId": "88bfb491-9e10-434f-c559-ccf1ef584e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heavily_augmented_trainset_transformations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms. RandomRotation(degrees=(30,120)),\n",
        "    transforms.RandomVerticalFlip(p=0.25),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=train_mean, std=train_std)\n",
        "])\n",
        "\n",
        "augmented_trainset_transformations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=train_mean, std=train_std)\n",
        "])\n"
      ],
      "metadata": {
        "id": "nnJ0y14FD1Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heavily_augmented_trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data/CIFAR10',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = heavily_augmented_trainset_transformations\n",
        ")\n",
        "\n",
        "augmented_trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data/CIFAR10',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = augmented_trainset_transformations\n",
        ")"
      ],
      "metadata": {
        "id": "jIBt-HGtJTyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction_loader = torch.utils.data.DataLoader(\n",
        "      dataset = normalized_testset,\n",
        "      batch_size = 10000,\n",
        "      num_workers = 1,\n",
        "      shuffle = True\n",
        "      )"
      ],
      "metadata": {
        "id": "5of6gCg-wRUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Factory: Custom CNN Architectures\n",
        "\n",
        "This section defines a modular CNN network factory used during experimentation.\n",
        "\n",
        "- The architecture is customizable and designed to work with the CIFAR-10 image size (32×32).\n",
        "- Convolutional layers are typically followed by Batch Normalization, ReLU activations, and Dropout for regularization.\n",
        "- The final output layer is adapted for 10-class classification.\n",
        "\n",
        "### How to Use Your Own Model\n",
        "\n",
        "To test a custom architecture:\n",
        "1. Add an elif statement with what you want to name your model\n",
        "2. Ensure the final output layer is: `nn.Linear(..., 10)`\n",
        "3. Make sure your model accepts inputs of shape `[batch_size, 32, 32, 3]` (for RGB CIFAR-10 images)\n",
        "4. Ensure you pass a '`torch.manual_seed()` before constructing your model, this will ensure the weights are reset if you want to test different hyperparameters with the same model\n"
      ],
      "metadata": {
        "id": "5hTlMQ_usPQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetworkFactory():\n",
        "  @staticmethod\n",
        "  def get_network(name):\n",
        "    if(name == 'CNN_model_vanilla'):\n",
        "      torch.manual_seed(50)\n",
        "      return nn.Sequential(\n",
        "          nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
        "          nn.ReLU(),\n",
        "          nn.Flatten(start_dim=1),\n",
        "          nn.Linear(in_features=12*24*24, out_features=120),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=120, out_features=60),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=60, out_features=10)\n",
        "      )\n",
        "\n",
        "    elif(name == 'CNN_model_Dropout_BNorm_Mpool'):\n",
        "        torch.manual_seed(50)\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.BatchNorm2d(6),\n",
        "\n",
        "            nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Linear(in_features=24*20*20, out_features=400),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(400),\n",
        "\n",
        "            nn.Linear(in_features=400, out_features=120),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(120),\n",
        "\n",
        "            nn.Linear(in_features=120, out_features=60),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(in_features=60, out_features=10)\n",
        "      )\n",
        "    elif(name == 'CNN_model_BNorm_Deep'):\n",
        "        torch.manual_seed(50)\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "\n",
        "            nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Linear(in_features=24*20*20, out_features=1200),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(in_features=1200, out_features=400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=400, out_features=120),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.BatchNorm1d(120),\n",
        "            nn.Linear(in_features=120, out_features=60),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=60, out_features=10)\n",
        "      )"
      ],
      "metadata": {
        "id": "WhCARW2WD2ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment Logging with RunManager\n",
        "\n",
        "The `RunManager` class automates the training workflow and logs key metrics for each hyperparameter configuration.\n",
        "\n",
        "- Each run is tracked with a unique ID and its parameter set (e.g., learning rate, batch size).\n",
        "- During training, loss and accuracy metrics are recorded per epoch.\n",
        "- After training, the results are compiled into a `pandas.DataFrame` for easy analysis, filtering, and visualization.\n",
        "\n",
        "### Output and Reusability\n",
        "\n",
        "- The final DataFrame includes hyperparameters, test accuracy, and optionally a saved state dict for the model.\n",
        "- This enables reproducibility and comparison across experiments.\n",
        "- Users can sort, export, or plot the DataFrame to evaluate which configuration performed best.\n",
        "\n"
      ],
      "metadata": {
        "id": "14jywG3vsx_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Epochstats():\n",
        "  def __init__(self):\n",
        "    self.number = 0\n",
        "    self.loss = 0\n",
        "    self.num_correct = 0\n",
        "    self.start_time = None\n",
        "    self.duration = None"
      ],
      "metadata": {
        "id": "dsDzsgK8LArT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Runstats():\n",
        "  def __init__(self):\n",
        "    self.params = None\n",
        "    self.number = 0\n",
        "    self.data = []\n",
        "    self.start_time = None\n",
        "    self.duration = None\n",
        "    self.test_accuracy = None"
      ],
      "metadata": {
        "id": "Kv2Dzv6iLZ9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunManager(Epochstats, Runstats):\n",
        "  def __init__(self):\n",
        "    self.model = None\n",
        "    self.loader= None\n",
        "    self.epoch = Epochstats()\n",
        "    self.run = Runstats()\n",
        "    self.model_files = []\n",
        "\n",
        "  def begin_run(self, run, model, loader):\n",
        "    self.run.start_time = time.time()\n",
        "    self.run.params = run\n",
        "    self.run.number += 1\n",
        "\n",
        "    self.run.test_accuracy = None\n",
        "\n",
        "    self.model = model\n",
        "    self.loader = loader\n",
        "\n",
        "\n",
        "  def end_run(self,):\n",
        "    self.epoch.number = 0\n",
        "\n",
        "    model_filename = f\"model_run_{self.run.number}.pth\"\n",
        "    torch.save(self.model.state_dict(), model_filename)\n",
        "    self.model_files.append(model_filename)\n",
        "\n",
        "  def begin_epoch(self):\n",
        "    self.epoch.start_time= time.time()\n",
        "\n",
        "    self.epoch.number += 1\n",
        "    self.epoch.loss = 0\n",
        "    self.epoch.num_correct = 0\n",
        "\n",
        "\n",
        "  def end_epoch(self):\n",
        "    self.epoch.duration = time.time() - self.epoch.start_time\n",
        "    self.run.duration = time.time() - self.run.start_time\n",
        "\n",
        "    loss = self.epoch.loss/len(self.loader.dataset)\n",
        "    accuracy = self.epoch.num_correct/len(self.loader.dataset)\n",
        "\n",
        "    results = OrderedDict()\n",
        "    results[\"run\"] = self.run.number\n",
        "    results[\"epoch\"] = self.epoch.number\n",
        "    results[\"loss\"] = loss\n",
        "    results[\"accuracy\"] = accuracy\n",
        "    results[\"epoch_duration\"] = self.epoch.duration\n",
        "    results[\"run_duration\"] = self.run.duration\n",
        "\n",
        "    for key,value in self.run.params._asdict().items():\n",
        "      results[key] = value\n",
        "\n",
        "    results[\"test_acc\"] = self.run.test_accuracy\n",
        "\n",
        "    self.run.data.append(results)\n",
        "\n",
        "    df = pd.DataFrame.from_dict(self.run.data, orient='columns')\n",
        "\n",
        "    clear_output(wait = True)\n",
        "    display(df)\n",
        "\n",
        "\n",
        "  def track_loss(self, loss):\n",
        "    self.epoch.loss += loss.item() * len(self.loader.dataset)\n",
        "\n",
        "\n",
        "  def track_num_correct(self, preds, labels):\n",
        "    self.epoch.num_correct += self.__get__num__correct(preds, labels)\n",
        "\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def __get__num__correct(self, pred, labels):\n",
        "    return pred.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def track_testing_accuracy(self, model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            preds = model(images)\n",
        "\n",
        "            predictions = preds.argmax(dim=1)\n",
        "            total += len(labels)\n",
        "            correct += (predictions == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    self.run.test_accuracy = accuracy"
      ],
      "metadata": {
        "id": "fLfOJPgwK6JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunBuilder():\n",
        "  @staticmethod\n",
        "  def get_runs(parameters):\n",
        "    Run = namedtuple('Run', parameters.keys())\n",
        "\n",
        "    runs = []\n",
        "\n",
        "    for v in product(*parameters.values()):\n",
        "      runs.append(Run(*v))\n",
        "\n",
        "    return runs"
      ],
      "metadata": {
        "id": "xMARZ69vJ8H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment Configuration Block\n",
        "\n",
        "This section provides a single, centralized place to configure and modify your experiment settings. Users can adjust the following:\n",
        "\n",
        "- `model`: Choose the architecture name as a string (e.g., `'Resnet'`, `'CNNModel'`, or any registered model).\n",
        "- `lr`: List of learning rates to try. You can provide multiple values for grid search (e.g., `[0.001, 0.0005]`).\n",
        "- `trainset`: Select the data preprocessing variant (`'normalized'`, `'augmented'`, `'heavily_augmented'`, etc.)\n",
        "\n",
        "Additional settings:\n",
        "- `batch_size`: Number of samples per training batch\n",
        "- `num_epochs`: Number of epochs to train each model\n",
        "- `weight_decay`: L2 regularization strength\n",
        "- `shuffle`: Whether to shuffle training data per epoch\n",
        "- `num_workers`: Number of subprocesses used for data loading\n",
        "\n",
        "## How to Use\n",
        "\n",
        "To test a new configuration:\n",
        "1. Modify values in the `parameters` dictionary.\n",
        "2. Add or remove entries in the lists to control grid search.\n",
        "3. Change `trainset` to control how data is preprocessed.\n",
        "4. Adjust `num_epochs`, `batch_size`, or `weight_decay` as needed.\n",
        "5. Run the notebook cells below to launch the new experiments.\n",
        "6. Additionally you can also add new fields to `parameters` dictionary to test different values for a hyperparameter in one go\n",
        "\n",
        "This design allows quick experimentation without needing to edit core logic or function signatures.\n"
      ],
      "metadata": {
        "id": "QNANIYlltDdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainsets = {\n",
        "    'normalized': normalized_trainset,\n",
        "    'not_normalized': raw_trainset,\n",
        "    'augmented': augmented_trainset,\n",
        "    'heavily_augmented':heavily_augmented_trainset\n",
        "}\n",
        "\n",
        "parameters = dict(\n",
        "    network = ['CNN_model_vanilla'],\n",
        "    lr = [0.001, 0.002],\n",
        "    trainset = ['augmented']\n",
        ")\n",
        "shuffle = True\n",
        "num_workers = 1 #@param {type: \"integer\"}\n",
        "batch_size = 1000 #@param {type: \"integer\"}\n",
        "num_epochs = 1 #@param {type: \"integer\"}\n",
        "weight_decay = 5e-2 #@param {type: \"number\"}"
      ],
      "metadata": {
        "id": "xP-wrykBKqpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Experimentation\n",
        "\n",
        "This section controls the core training loop and experiment execution. It uses a custom `RunManager` class to:\n",
        "\n",
        "- Automate training over multiple hyperparameter combinations\n",
        "- Track and log loss, training accuracy, and testing accuracy (to check for overfitting) per run\n",
        "- Reset and reinitialize model weights for each configuration\n",
        "- Output the results into a well-formatted pandas DataFrame\n",
        "\n",
        "Each run corresponds to a unique combination on the basis of the fields entered in `parameters` in the configuration block\n",
        "\n",
        "The structured logging system allows users to:\n",
        "- Identify top-performing configurations\n",
        "- Compare test accuracy across models and settings\n",
        "- Extend the framework by plugging in new optimizers, loss functions, or models\n"
      ],
      "metadata": {
        "id": "OuGkv6-RQWjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "manager = RunManager()\n",
        "\n",
        "for run in RunBuilder.get_runs(parameters):\n",
        "  model = NetworkFactory.get_network(run.network).to(device)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "      dataset = trainsets[run.trainset],\n",
        "      batch_size = batch_size,\n",
        "      num_workers = num_workers\n",
        "  )\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=run.lr, weight_decay=weight_decay)\n",
        "\n",
        "  manager.begin_run(run=run, model=model, loader=train_loader)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    manager.begin_epoch()\n",
        "\n",
        "    for batch in train_loader:\n",
        "      images = batch[0].to(device)\n",
        "      labels = batch[1].to(device)\n",
        "      preds = model(images)\n",
        "\n",
        "      loss = F.cross_entropy(preds, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      manager.track_loss(loss)\n",
        "      manager.track_num_correct(preds, labels)\n",
        "\n",
        "    if epoch <= num_epochs-1:\n",
        "          manager.track_testing_accuracy(model, test_prediction_loader)\n",
        "    manager.end_epoch()\n",
        "  manager.end_run()\n",
        "\n",
        "for filepath in manager.model_files:\n",
        "  print(f\"Model saved: {filepath}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "cOyMrD8TTuND",
        "outputId": "6adc1269-774f-4f83-c77a-62f7a6a1a846",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   run  epoch        loss  accuracy  epoch_duration  run_duration  \\\n",
              "0    1      1  105.579627   0.22642       38.186993     38.187014   \n",
              "1    2      1  103.934432   0.23786       38.201097     38.201121   \n",
              "\n",
              "               model     lr   trainset  test_acc  \n",
              "0  CNN_model_vanilla  0.001  augmented    0.3128  \n",
              "1  CNN_model_vanilla  0.002  augmented    0.3172  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0abcc77-340a-4298-8e06-800c1e4b10f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>epoch_duration</th>\n",
              "      <th>run_duration</th>\n",
              "      <th>model</th>\n",
              "      <th>lr</th>\n",
              "      <th>trainset</th>\n",
              "      <th>test_acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>105.579627</td>\n",
              "      <td>0.22642</td>\n",
              "      <td>38.186993</td>\n",
              "      <td>38.187014</td>\n",
              "      <td>CNN_model_vanilla</td>\n",
              "      <td>0.001</td>\n",
              "      <td>augmented</td>\n",
              "      <td>0.3128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>103.934432</td>\n",
              "      <td>0.23786</td>\n",
              "      <td>38.201097</td>\n",
              "      <td>38.201121</td>\n",
              "      <td>CNN_model_vanilla</td>\n",
              "      <td>0.002</td>\n",
              "      <td>augmented</td>\n",
              "      <td>0.3172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0abcc77-340a-4298-8e06-800c1e4b10f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0abcc77-340a-4298-8e06-800c1e4b10f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0abcc77-340a-4298-8e06-800c1e4b10f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c005c6db-9df4-448b-bceb-2a160626fb00\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c005c6db-9df4-448b-bceb-2a160626fb00')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c005c6db-9df4-448b-bceb-2a160626fb00 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  print(f\\\"Model saved: {filepath}\\\")\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"run\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1633287146406008,\n        \"min\": 103.93443179130554,\n        \"max\": 105.57962703704834,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          103.93443179130554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008089301576774089,\n        \"min\": 0.22642,\n        \"max\": 0.23786,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.23786\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epoch_duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009973124469435832,\n        \"min\": 38.18699336051941,\n        \"max\": 38.20109748840332,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          38.20109748840332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009975484692952443,\n        \"min\": 38.18701362609863,\n        \"max\": 38.20112109184265,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          38.20112109184265\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CNN_model_vanilla\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007071067811865475,\n        \"min\": 0.001,\n        \"max\": 0.002,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trainset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"augmented\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0031112698372207804,\n        \"min\": 0.3128,\n        \"max\": 0.3172,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.3172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved: model_run_1.pth\n",
            "Model saved: model_run_2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Model Download and Cleanup Interface\n",
        "\n",
        "After training multiple models using the experimentation framework, this cell enables users to selectively download specific model checkpoints while managing Colab memory effectively.\n",
        "\n",
        "###  Features:\n",
        "- Input a run number (e.g., `1`) to fetch `model_run_1.pth`\n",
        "- Provide a custom name (e.g., `CNN_vanilla`) to rename the download file to `CNN_vanilla.pth`\n",
        "- File is downloaded and immediately deleted from the Colab disk after user confirmation\n",
        "- Continue downloading more files, or exit anytime\n",
        "- Automatically clears all original `.pth` files after process ends\n",
        "\n",
        "###  How to Use:\n",
        "1. **When prompted**:  \n",
        "   `Enter model run to download (E to exit):`  \n",
        "     Type the run number (e.g., `3`) to download `model_run_3.pth`\n",
        "\n",
        "2. **When prompted**:  \n",
        "   `Rename the file to (do not include the .pth extension):`  \n",
        "     Enter your custom name (e.g., `my_cnn_model`)  \n",
        "     Final file will be downloaded as `my_cnn_model.pth`\n",
        "\n",
        "3. Once the download starts, confirm it's complete\n",
        "\n",
        "4. To exit the loop, type `E` at the run prompt\n",
        "\n",
        "###  Notes:\n",
        "- Invalid characters or spaces in filenames are automatically replaced with `_`\n",
        "- Files are copied (not renamed) to preserve originals until final cleanup\n",
        "- This ensures Colab storage remains clean and prevents memory overflow\n",
        "\n"
      ],
      "metadata": {
        "id": "g1V98uWRiMtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_model_files = [f for f in os.listdir() if f.endswith('.pth')]\n",
        "downloaded = set()\n",
        "print(\"Available model files:\")\n",
        "print(all_model_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMYevCHgZvFc",
        "outputId": "ba40d994-c6df-4a96-d5ae-64652b50278b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available model files:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while len(downloaded) < len(all_model_files):\n",
        "  run_number = input(\"\\nEnter model run to download(E to exit): \").strip()\n",
        "\n",
        "  if run_number == \"E\" or \"e\":\n",
        "    break\n",
        "\n",
        "  fileaddress = f\"model_run_{run_number}.pth\"\n",
        "\n",
        "  if fileaddress not in all_model_files:\n",
        "    print(f\"{fileaddress} does not exist or has already been downloaded\")\n",
        "    break\n",
        "\n",
        "  new_name = input(\"Rename the file to (do not include the .pth extension): \").strip()\n",
        "  new_name = re.sub(r'[^\\w\\-_.]', '_', new_name.strip())\n",
        "  new_fileaddress = f\"{new_name}.pth\"\n",
        "  shutil.copy(fileaddress, new_fileaddress)\n",
        "\n",
        "  print(f\"Downloading run {run_number} to local machine as {new_fileaddress}\")\n",
        "\n",
        "  files.download(new_fileaddress)\n",
        "  input(\"Please Enter AFTER the file has downloaded to continue\")\n",
        "\n",
        "  if os.path.exists(new_fileaddress):\n",
        "    os.remove(new_fileaddress)\n",
        "    print(f\"Deleted {new_fileaddress} from colab disc\")\n",
        "\n",
        "  downloaded.add(fileaddress)\n",
        "  print(f\"{fileaddress} saved to local device as {new_fileaddress}\")\n",
        "\n",
        "  if len(downloaded) == len(all_model_files):\n",
        "    print(\"All files downloaded\")\n",
        "\n",
        "  next_action = input(\"Press A to add more files, or E to exit\").strip()\n",
        "\n",
        "  if next_action == \"e\" or \"E\":\n",
        "    break\n",
        "\n",
        "for f in all_model_files:\n",
        "        if os.path.exists(f):\n",
        "            os.remove(f)\n",
        "\n",
        "print(\"\\nAll original model files have been removed from Colab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaWxUmtfZ94e",
        "outputId": "c722b2a8-e8c9-4087-e450-f63841e86fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All original model files have been removed from Colab.\n"
          ]
        }
      ]
    }
  ]
}